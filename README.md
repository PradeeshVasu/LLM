# ğŸ§  LLM-Based RAG System â€“ AI-Powered Knowledge Assistant

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-success?logo=fastapi)
![React](https://img.shields.io/badge/React-Frontend-61DAFB?logo=react)
![TypeScript](https://img.shields.io/badge/TypeScript-Used-blue?logo=typescript)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Build-Passing-brightgreen)
![Platform](https://img.shields.io/badge/Platform-Web-lightgrey)

---

## ğŸ“– Overview

**LLM using RAG (Retrieval-Augmented Generation)** is an AI-driven question-answering system that combines **document retrieval** with **Large Language Models (LLMs)** to deliver **accurate, context-aware responses** from uploaded PDFs.

The application allows users to:
- Upload large PDF files (such as policies, reports, or papers)  
- Query the documents through **text or voice**
- Receive **real-time, AI-generated summaries and answers**

This project integrates:
- A **FastAPI backend** for PDF ingestion, embedding, and RAG logic  
- A **React + TypeScript frontend** for a dynamic, user-friendly experience

---

## ğŸš€ Key Features

âœ… **PDF Upload and Parsing** â€” Extracts text using advanced PDF parsers  
âœ… **Retrieval-Augmented Generation (RAG)** â€” Combines LLM reasoning with vector search  
âœ… **Voice Interaction** â€” Accepts and responds via speech  
âœ… **LLM-Powered Summarization** â€” Generates high-quality insights  
âœ… **Chat History Export** â€” Downloadable in PDF format  
âœ… **Fast & Modern UI** â€” Built with React + TypeScript  
âœ… **Secure and Modular Backend** â€” Using FastAPI and Uvicorn  

---

## ğŸ§© Tech Stack

| Category | Technologies Used |
|-----------|-------------------|
| **Programming Language** | Python 3.10, TypeScript |
| **Backend Framework** | FastAPI |
| **Frontend Framework** | React.js + Vite / CRA |
| **LLM / NLP** | LangChain, OpenAI API |
| **Vector Database** | FAISS / Chroma |
| **PDF Processing** | pdfplumber, PyMuPDF |
| **Audio & Speech** | pyttsx3, SpeechRecognition |
| **Server** | Uvicorn |

---

## ğŸ“ Folder Structure

```

ğŸ“¦ LLM_RAG_System/
â”‚
â”œâ”€â”€ ğŸ“ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ llm_handler.py
â”‚   â”œâ”€â”€ pdf_utils.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vector_store.pkl
â”‚   â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ model.pkl
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â”œâ”€â”€ App.test.tsx
â”‚   â”‚   â”œâ”€â”€ index.tsx
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBox.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceInput.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ResponseCard.tsx
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ api.ts
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

````

---

## âš™ï¸ Installation & Setup

### ğŸ§© Backend Setup

1ï¸âƒ£ **Navigate to backend**
```bash
cd backend
````

2ï¸âƒ£ **Create and activate a virtual environment**

```bash
python -m venv venv
venv\Scripts\activate   # Windows
# or
source venv/bin/activate   # Linux/Mac
```

3ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Run the FastAPI server**

```bash
uvicorn app:app --reload --port 8000
```

â¡ï¸ **Backend running at:** [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

### ğŸ’» Frontend Setup

1ï¸âƒ£ **Navigate to frontend**

```bash
cd frontend
```

2ï¸âƒ£ **Install dependencies**

```bash
npm install
```

3ï¸âƒ£ **Run the development server**

```bash
npm start
```

â¡ï¸ **Frontend running at:** [http://localhost:3000](http://localhost:3000)

---

## ğŸ”— Connecting Frontend & Backend

To connect both servers, add your backend API endpoint inside the `.env` file in `frontend/`:

```
REACT_APP_API_URL=http://127.0.0.1:8000
```

---

## âš™ï¸ How It Works

1. **User uploads a PDF** â†’ text and embeddings are extracted
2. **Query sent** â†’ LLM processes query with document context
3. **Vector search** â†’ Top-k relevant chunks retrieved
4. **RAG pipeline** â†’ LLM generates factual response
5. **Response displayed** â†’ Text + optional speech output
6. **Transcript saved** â†’ Downloadable as PDF

---

## ğŸ§ª Example Queries

| Example Query                        | Response Summary                                                                            |
| ------------------------------------ | ------------------------------------------------------------------------------------------- |
| â€œSummarize this education policy.â€   | Returns a structured summary highlighting goals, target groups, and implementation details. |
| â€œWhat AI initiatives are mentioned?â€ | Lists and explains each AI-related scheme in the document.                                  |
| â€œWho are the key beneficiaries?â€     | Extracts and lists stakeholders or target demographics.                                     |

---

## ğŸ§° Commands Summary

| Task                              | Command                           |
| --------------------------------- | --------------------------------- |
| **Run Backend (FastAPI)**         | `uvicorn app:app --reload`        |
| **Install Backend Dependencies**  | `pip install -r requirements.txt` |
| **Run Frontend (React)**          | `npm start`                       |
| **Install Frontend Dependencies** | `npm install`                     |

---

## ğŸ“½ï¸ Model Demo Prototye 

<img width="1919" height="1134" alt="Screenshot 2025-11-02 141425" src="https://github.com/user-attachments/assets/2b2a8bd3-0e7c-4007-9c10-60948645a9fc" />

<img width="1915" height="1136" alt="Screenshot 2025-11-02 142343" src="https://github.com/user-attachments/assets/ec5a8383-3e1b-4b1c-a481-039a97377b7a" />

<img width="1919" height="1131" alt="Screenshot 2025-11-02 142438" src="https://github.com/user-attachments/assets/18196a5d-ab5a-40e3-92f2-45292270ba40" />

---

## ğŸ‘¨â€ğŸ’» Author

**Pradeesh Vasu**                       
ğŸ“§ Email: [pradeeshvasu22@gmail.com](mailto:pradeeshvasu22@gmail.com)              
ğŸ”— LinkedIn: [linkedin.com/in/pradeesh-vasu-03486b319](https://www.linkedin.com/in/pradeesh-vasu-03486b319)                  
ğŸ™ GitHub: [github.com/PradeeshVasu](https://github.com/PradeeshVasu)

---

## ğŸªª License

This project is licensed under the **MIT License** â€“ you are free to use, modify, and distribute it for educational and research purposes.

---

## â­ Support

If you like this project, please â­ **star this repository** on GitHub and share it with others who might find it useful.

---

## ğŸ§­ Version Info

| Component     | Version |
| ------------- | ------- |
| **Python**    | 3.10    |
| **FastAPI**   | â‰¥0.110  |
| **React**     | 18+     |
| **Node.js**   | â‰¥18     |
| **LangChain** | 0.2+    |

---
